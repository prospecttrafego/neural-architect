# PARTE 5: DOCUMENT GENERATOR E DEPLOY

## 11. FEATURE 4: DOCUMENT GENERATOR

### 11.1 TIS Generator

```python
# backend/app/ai/generators/tis_generator.py
from typing import Any
from agno.agent import Agent
from agno.models.anthropic import Claude


TIS_SYSTEM_PROMPT = """Voc√™ √© um gerador de TIS (Technical Implementation Spec).

O TIS √© um documento extremamente espec√≠fico e execut√°vel, projetado para que uma IA (Claude, Cursor, Replit) possa implementar o projeto sem ambiguidade.

ESTRUTURA DO TIS:

```markdown
# TIS - [Nome do Projeto]
## Technical Implementation Specification
### Gerado por Neural Architect | [Data]

---

## 1. CONTEXTO
[2 par√°grafos: O que √©, para quem, problema que resolve]

## 2. STACK EXATO
```yaml
frontend:
  framework: [especificar vers√£o exata]
  ...
backend:
  ...
database:
  ...
```

## 3. ESTRUTURA DE PASTAS
```
project/
‚îú‚îÄ‚îÄ ...
```

## 4. SCHEMAS
[C√≥digo real: Zod, Pydantic, SQL]

## 5. IMPLEMENTA√á√ÉO POR FEATURE
### Feature 1: [Nome]
**Arquivos a criar:**
- [ ] `path/to/file`

**Depend√™ncias:**
- ...

**C√≥digo de exemplo:**
```language
// c√≥digo espec√≠fico
```

**Acceptance criteria:**
- [ ] Crit√©rio t√©cnico 1
- [ ] Crit√©rio t√©cnico 2

## 6. REGRAS DE IMPLEMENTA√á√ÉO
- ‚úÖ Fazer: [lista]
- ‚ùå N√£o fazer: [lista]

## 7. DEPLOY
[Instru√ß√µes de deploy]
```

REGRAS:
1. SEJA EXTREMAMENTE ESPEC√çFICO - nenhuma ambiguidade
2. Use vers√µes exatas de todas as depend√™ncias
3. Inclua c√≥digo real, n√£o pseudo-c√≥digo
4. Cada feature deve ter arquivos, c√≥digo e crit√©rios claros
5. O documento deve ser auto-contido
"""


async def generate_tis(
    project_name: str,
    project_description: str,
    canvas_state: dict[str, Any],
    category: str
) -> str:
    """
    Generate TIS document from canvas state.
    
    Args:
        project_name: Name of the project
        project_description: Description
        canvas_state: Current canvas with nodes and edges
        category: Project category (software, agents, automation)
    
    Returns:
        Complete TIS document in markdown
    """
    # Build context from canvas
    nodes = canvas_state.get("nodes", [])
    edges = canvas_state.get("edges", [])
    
    canvas_description = _describe_canvas(nodes, edges, category)
    
    # Create agent for generation
    agent = Agent(
        model=Claude(id="claude-sonnet-4-20250514"),
        instructions=TIS_SYSTEM_PROMPT,
        markdown=True
    )
    
    prompt = f"""Gere um TIS completo para o seguinte projeto:

**Nome:** {project_name}
**Descri√ß√£o:** {project_description}
**Categoria:** {category}

**Estrutura do Canvas:**
{canvas_description}

Gere o documento TIS completo seguindo a estrutura especificada.
Use o stack tecnol√≥gico mais apropriado para {category} em dezembro de 2025.
Seja extremamente espec√≠fico e inclua c√≥digo real.
"""
    
    response = await agent.arun(prompt)
    return response.content


def _describe_canvas(nodes: list, edges: list, category: str) -> str:
    """Convert canvas to text description."""
    if not nodes:
        return "Canvas vazio - gere uma arquitetura b√°sica apropriada"
    
    description = []
    
    # Describe nodes by type
    node_types = {}
    for node in nodes:
        node_type = node.get("type", "unknown")
        if node_type not in node_types:
            node_types[node_type] = []
        node_types[node_type].append(node.get("data", {}).get("label", "Unnamed"))
    
    description.append("### Componentes:")
    for node_type, labels in node_types.items():
        description.append(f"- **{node_type}**: {', '.join(labels)}")
    
    # Describe connections
    if edges:
        description.append("\n### Fluxo:")
        for edge in edges:
            source = _find_node_label(nodes, edge.get("source"))
            target = _find_node_label(nodes, edge.get("target"))
            label = edge.get("label", "‚Üí")
            description.append(f"- {source} {label} {target}")
    
    return "\n".join(description)


def _find_node_label(nodes: list, node_id: str) -> str:
    """Find node label by ID."""
    for node in nodes:
        if node.get("id") == node_id:
            return node.get("data", {}).get("label", node_id)
    return node_id
```

### 11.2 PRD Generator

```python
# backend/app/ai/generators/prd_generator.py
from typing import Any
from agno.agent import Agent
from agno.models.anthropic import Claude


PRD_SYSTEM_PROMPT = """Voc√™ √© um gerador de PRD (Product Requirements Document).

O PRD √© um documento de alto n√≠vel para stakeholders e desenvolvedores humanos, focado em valor de neg√≥cio e requisitos funcionais.

ESTRUTURA DO PRD:

```markdown
# PRD - [Nome do Projeto]
## Product Requirements Document
### Vers√£o 1.0 | [Data]

---

## 1. VIS√ÉO GERAL

### 1.1 Problema
[Qual problema estamos resolvendo?]

### 1.2 Solu√ß√£o
[Como resolvemos?]

### 1.3 P√∫blico-Alvo
[Para quem √©?]

## 2. OBJETIVOS E M√âTRICAS

### 2.1 Objetivos
- Objetivo 1
- Objetivo 2

### 2.2 M√©tricas de Sucesso (KPIs)
| M√©trica | Meta | Como medir |
|---------|------|------------|
| ... | ... | ... |

## 3. REQUISITOS FUNCIONAIS

### 3.1 User Stories

#### Epic 1: [Nome]

**US-001: [T√≠tulo]**
- Como [persona]
- Quero [a√ß√£o]
- Para [benef√≠cio]

**Crit√©rios de Aceite:**
- [ ] Crit√©rio 1
- [ ] Crit√©rio 2

## 4. REQUISITOS N√ÉO-FUNCIONAIS

### 4.1 Performance
- ...

### 4.2 Seguran√ßa
- ...

### 4.3 Escalabilidade
- ...

## 5. ARQUITETURA DE ALTO N√çVEL

[Descri√ß√£o da arquitetura]

## 6. ESCOPO E LIMITA√á√ïES

### 6.1 Dentro do Escopo
- ...

### 6.2 Fora do Escopo (v1)
- ...

## 7. RISCOS E MITIGA√á√ïES

| Risco | Impacto | Probabilidade | Mitiga√ß√£o |
|-------|---------|---------------|-----------|
| ... | ... | ... | ... |

## 8. TIMELINE

| Fase | Dura√ß√£o | Entreg√°veis |
|------|---------|-------------|
| ... | ... | ... |
```

REGRAS:
1. Foque em valor de neg√≥cio, n√£o em implementa√ß√£o t√©cnica
2. Use linguagem clara para n√£o-t√©cnicos
3. Inclua m√©tricas mensur√°veis
4. Seja realista sobre escopo e riscos
"""


async def generate_prd(
    project_name: str,
    project_description: str,
    canvas_state: dict[str, Any],
    category: str
) -> str:
    """Generate PRD document from canvas state."""
    nodes = canvas_state.get("nodes", [])
    edges = canvas_state.get("edges", [])
    
    canvas_description = _describe_canvas_for_prd(nodes, edges)
    
    agent = Agent(
        model=Claude(id="claude-sonnet-4-20250514"),
        instructions=PRD_SYSTEM_PROMPT,
        markdown=True
    )
    
    prompt = f"""Gere um PRD completo para:

**Nome:** {project_name}
**Descri√ß√£o:** {project_description}

**Arquitetura Planejada:**
{canvas_description}

Gere o documento PRD completo focando em valor de neg√≥cio e requisitos.
"""
    
    response = await agent.arun(prompt)
    return response.content


def _describe_canvas_for_prd(nodes: list, edges: list) -> str:
    """Convert canvas to business-friendly description."""
    if not nodes:
        return "Arquitetura ainda n√£o definida"
    
    # Extract high-level components
    components = []
    for node in nodes:
        label = node.get("data", {}).get("label", "")
        description = node.get("data", {}).get("description", "")
        if label:
            components.append(f"- {label}: {description}" if description else f"- {label}")
    
    return "Componentes principais:\n" + "\n".join(components)
```

### 11.3 Agent Spec Generator

```python
# backend/app/ai/generators/agent_spec_generator.py
from typing import Any
from agno.agent import Agent
from agno.models.anthropic import Claude


AGENT_SPEC_PROMPT = """Voc√™ √© um gerador de Agent Specification.

Este documento especifica completamente um sistema de agentes IA, incluindo system prompts, tools, e configura√ß√µes.

ESTRUTURA:

```markdown
# Agent Specification - [Nome]
## Sistema Multi-Agente
### Gerado por Neural Architect | [Data]

---

## 1. VIS√ÉO GERAL DO SISTEMA

### 1.1 Objetivo
[O que o sistema de agentes faz]

### 1.2 Arquitetura
[Single agent / Multi-agent / Swarm]

## 2. AGENTES

### Agent: [Nome]

**Role:** [Papel do agente]
**Goal:** [Objetivo]
**Backstory:** [Contexto/hist√≥ria]

**System Prompt:**
```
[System prompt completo]
```

**Tools:**
| Tool | Descri√ß√£o | Input | Output |
|------|-----------|-------|--------|
| ... | ... | ... | ... |

**Configura√ß√£o:**
```python
agent = Agent(
    model=...,
    tools=[...],
    instructions="...",
    ...
)
```

## 3. WORKFLOW

### 3.1 Fluxo de Execu√ß√£o
[Descri√ß√£o do fluxo]

### 3.2 Comunica√ß√£o entre Agentes
[Como os agentes se comunicam]

## 4. TOOLS DETALHADAS

### Tool: [Nome]

```python
@tool
def tool_name(param: type) -> return_type:
    \"\"\"
    Descri√ß√£o detalhada.
    
    Args:
        param: descri√ß√£o
    
    Returns:
        descri√ß√£o
    \"\"\"
    # Implementa√ß√£o
    pass
```

## 5. KNOWLEDGE BASE

### 5.1 Fontes de Dados
- ...

### 5.2 Estrat√©gia de RAG
- ...

## 6. CONFIGURA√á√ïES DE DEPLOY

```yaml
model: pesquisar melhor op√ß√£o
temperature: 0.7
max_tokens: 4096
...
```

## 7. EXEMPLOS DE USO

### Exemplo 1: [Cen√°rio]
**Input:**
```
[exemplo de input]
```

**Output esperado:**
```
[exemplo de output]
```
```
"""


async def generate_agent_spec(
    project_name: str,
    project_description: str,
    canvas_state: dict[str, Any]
) -> str:
    """Generate Agent Specification from canvas."""
    nodes = canvas_state.get("nodes", [])
    edges = canvas_state.get("edges", [])
    
    # Extract agent nodes
    agents = [n for n in nodes if n.get("type") == "agent"]
    tools = [n for n in nodes if n.get("type") == "tool"]
    knowledge = [n for n in nodes if n.get("type") == "knowledge"]
    
    agent = Agent(
        model=Claude(id="claude-sonnet-4-20250514"),
        instructions=AGENT_SPEC_PROMPT,
        markdown=True
    )
    
    prompt = f"""Gere uma Agent Specification completa para:

**Nome:** {project_name}
**Descri√ß√£o:** {project_description}

**Agentes identificados:**
{_format_agents(agents)}

**Tools dispon√≠veis:**
{_format_tools(tools)}

**Knowledge bases:**
{_format_knowledge(knowledge)}

**Conex√µes:**
{_format_edges(edges, nodes)}

Gere a especifica√ß√£o completa incluindo system prompts detalhados.
"""
    
    response = await agent.arun(prompt)
    return response.content


def _format_agents(agents: list) -> str:
    if not agents:
        return "Nenhum agente definido - sugira agentes apropriados"
    
    lines = []
    for a in agents:
        data = a.get("data", {})
        lines.append(f"- {data.get('label', 'Agent')}: {data.get('description', '')}")
    return "\n".join(lines)


def _format_tools(tools: list) -> str:
    if not tools:
        return "Nenhuma tool definida"
    
    lines = []
    for t in tools:
        data = t.get("data", {})
        lines.append(f"- {data.get('label', 'Tool')}: {data.get('description', '')}")
    return "\n".join(lines)


def _format_knowledge(knowledge: list) -> str:
    if not knowledge:
        return "Nenhuma knowledge base definida"
    
    lines = []
    for k in knowledge:
        data = k.get("data", {})
        lines.append(f"- {data.get('label', 'KB')}: {data.get('description', '')}")
    return "\n".join(lines)


def _format_edges(edges: list, nodes: list) -> str:
    if not edges:
        return "Sem conex√µes definidas"
    
    def get_label(node_id):
        for n in nodes:
            if n.get("id") == node_id:
                return n.get("data", {}).get("label", node_id)
        return node_id
    
    lines = []
    for e in edges:
        source = get_label(e.get("source"))
        target = get_label(e.get("target"))
        label = e.get("label", "‚Üí")
        lines.append(f"- {source} {label} {target}")
    return "\n".join(lines)
```

### 11.4 Document API Endpoint

```python
# backend/app/api/v1/endpoints/documents.py
from uuid import UUID
from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession

from app.api.deps import get_db
from app.api.v1.schemas.document import (
    GenerateDocument, DocumentResponse, DocumentListResponse
)
from app.services.document_service import DocumentService
from app.services.project_service import ProjectService
from app.services.canvas_service import CanvasService

router = APIRouter(prefix="/documents", tags=["documents"])


@router.get("/project/{project_id}", response_model=DocumentListResponse)
async def list_documents(
    project_id: UUID,
    db: AsyncSession = Depends(get_db)
):
    """List all generated documents for a project."""
    service = DocumentService(db)
    documents = await service.list_documents(project_id)
    return DocumentListResponse(items=documents, total=len(documents))


@router.post("/project/{project_id}/generate", response_model=DocumentResponse)
async def generate_document(
    project_id: UUID,
    data: GenerateDocument,
    db: AsyncSession = Depends(get_db)
):
    """Generate a new document (TIS, PRD, Agent Spec, etc.)."""
    # Get project
    project_service = ProjectService(db)
    project = await project_service.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")
    
    # Get canvas
    canvas_service = CanvasService(db)
    canvas = await canvas_service.get_main_canvas(project_id)
    if not canvas:
        raise HTTPException(status_code=404, detail="Canvas not found")
    
    # Generate document
    document_service = DocumentService(db)
    document = await document_service.generate_document(
        project=project,
        canvas=canvas,
        doc_type=data.doc_type,
        options=data.options
    )
    
    return document


@router.get("/{document_id}", response_model=DocumentResponse)
async def get_document(
    document_id: UUID,
    db: AsyncSession = Depends(get_db)
):
    """Get a specific document."""
    service = DocumentService(db)
    document = await service.get_document(document_id)
    if not document:
        raise HTTPException(status_code=404, detail="Document not found")
    return document


@router.delete("/{document_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_document(
    document_id: UUID,
    db: AsyncSession = Depends(get_db)
):
    """Delete a document."""
    service = DocumentService(db)
    success = await service.delete_document(document_id)
    if not success:
        raise HTTPException(status_code=404, detail="Document not found")
```

---

## 12. DEPLOY CONFIGURATION

### 12.1 Dockerfile - Frontend

```dockerfile
# docker/Dockerfile.frontend
FROM node:20-alpine AS builder

WORKDIR /app

# Install pnpm
RUN corepack enable && corepack prepare pnpm@latest --activate

# Copy package files
COPY frontend/package.json frontend/pnpm-lock.yaml ./

# Install dependencies
RUN pnpm install --frozen-lockfile

# Copy source
COPY frontend/ .

# Build
RUN pnpm build

# Production image
FROM nginx:alpine

# Copy built files
COPY --from=builder /app/dist /usr/share/nginx/html

# Copy nginx config
COPY docker/nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### 12.2 Dockerfile - Backend

```dockerfile
# docker/Dockerfile.backend
FROM python:3.12-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install uv
RUN pip install uv

# Copy dependency files
COPY backend/pyproject.toml backend/uv.lock ./

# Install dependencies
RUN uv sync --frozen

# Copy source
COPY backend/ .

# Create uploads directory
RUN mkdir -p /app/uploads

# Expose port
EXPOSE 8000

# Run with uvicorn
CMD ["uv", "run", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 12.3 Docker Compose

```yaml
# docker/docker-compose.yml
version: '5.0.0'

services:
  # ==========================================================================
  # FRONTEND
  # ==========================================================================
  frontend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.frontend
    ports:
      - "3000:80"
    environment:
      - VITE_API_URL=http://backend:8000
    depends_on:
      - backend
    networks:
      - neural-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`${DOMAIN:-localhost}`)"
      - "traefik.http.routers.frontend.entrypoints=websecure"
      - "traefik.http.routers.frontend.tls.certresolver=letsencrypt"
      - "traefik.http.services.frontend.loadbalancer.server.port=80"

  # ==========================================================================
  # BACKEND
  # ==========================================================================
  backend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.backend
    ports:
      - "8000:8000"
    environment:
      - APP_ENV=production
      - DEBUG=false
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=postgresql+asyncpg://postgres:${POSTGRES_PASSWORD}@db:5432/neural_architect
      - REDIS_URL=redis://redis:6379/0
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - CORS_ORIGINS=["https://${DOMAIN:-localhost}"]
    volumes:
      - uploads:/app/uploads
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - neural-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=Host(`${DOMAIN:-localhost}`) && PathPrefix(`/api`)"
      - "traefik.http.routers.backend.entrypoints=websecure"
      - "traefik.http.routers.backend.tls.certresolver=letsencrypt"
      - "traefik.http.services.backend.loadbalancer.server.port=8000"

  # ==========================================================================
  # DATABASE
  # ==========================================================================
  db:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=neural_architect
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ../backend/migrations/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - neural-network

  # ==========================================================================
  # REDIS
  # ==========================================================================
  redis:
    image: redis:8.4.0-alpine
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - neural-network

  # ==========================================================================
  # TRAEFIK (Reverse Proxy + SSL)
  # ==========================================================================
  traefik:
    image: traefik:v3.7.0
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--certificatesresolvers.letsencrypt.acme.tlschallenge=true"
      - "--certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}"
      - "--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json"
      # Redirect HTTP to HTTPS
      - "--entrypoints.web.http.redirections.entryPoint.to=websecure"
      - "--entrypoints.web.http.redirections.entryPoint.scheme=https"
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # Traefik dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - letsencrypt:/letsencrypt
    networks:
      - neural-network

networks:
  neural-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  uploads:
  letsencrypt:
```

### 12.4 Environment Variables Template

```bash
# .env.example

# =============================================================================
# APP
# =============================================================================
DOMAIN=neural-architect.seudominio.com
SECRET_KEY=your-secret-key-min-32-characters-here

# =============================================================================
# DATABASE
# =============================================================================
POSTGRES_PASSWORD=your-secure-password-here

# =============================================================================
# AI APIS
# =============================================================================
ANTHROPIC_API_KEY=sk-ant-xxxxx
OPENAI_API_KEY=sk-xxxxx

# =============================================================================
# SSL
# =============================================================================
ACME_EMAIL=seu@email.com
```

### 12.5 EasyPanel Setup Script

```bash
#!/bin/bash
# scripts/setup-easypanel.sh

# =============================================================================
# Neural Architect - EasyPanel Setup
# =============================================================================

set -e

echo "üöÄ Configurando Neural Architect no EasyPanel..."

# Check if running as root
if [ "$EUID" -ne 0 ]; then
  echo "‚ùå Execute como root (sudo)"
  exit 1
fi

# =============================================================================
# 1. Install Docker (if not installed)
# =============================================================================
if ! command -v docker &> /dev/null; then
    echo "üì¶ Instalando Docker..."
    curl -fsSL https://get.docker.com | sh
fi

# =============================================================================
# 2. Install EasyPanel
# =============================================================================
if ! docker ps | grep -q easypanel; then
    echo "üì¶ Instalando EasyPanel..."
    docker run --rm -it \
        -v /etc/easypanel:/etc/easypanel \
        -v /var/run/docker.sock:/var/run/docker.sock:ro \
        easypanel/easypanel setup
fi

# =============================================================================
# 3. Open Firewall Ports
# =============================================================================
echo "üî• Configurando firewall..."
ufw allow 80/tcp
ufw allow 443/tcp
ufw allow 3000/tcp  # EasyPanel dashboard
ufw --force enable

# =============================================================================
# 4. Create Project Directory
# =============================================================================
PROJECT_DIR="/opt/neural-architect"
mkdir -p $PROJECT_DIR
cd $PROJECT_DIR

# =============================================================================
# 5. Clone Repository (or copy files)
# =============================================================================
echo "üì• Baixando c√≥digo..."
# git clone https://github.com/seu-usuario/neural-architect.git .

# =============================================================================
# 6. Create .env file
# =============================================================================
if [ ! -f .env ]; then
    echo "üìù Criando arquivo .env..."
    cp .env.example .env
    
    # Generate secret key
    SECRET_KEY=$(openssl rand -hex 32)
    sed -i "s/your-secret-key-min-32-characters-here/$SECRET_KEY/" .env
    
    # Generate DB password
    DB_PASSWORD=$(openssl rand -hex 16)
    sed -i "s/your-secure-password-here/$DB_PASSWORD/" .env
    
    echo "‚ö†Ô∏è  Configure as chaves de API no arquivo .env:"
    echo "    - ANTHROPIC_API_KEY"
    echo "    - OPENAI_API_KEY"
    echo "    - DOMAIN"
    echo "    - ACME_EMAIL"
fi

echo ""
echo "‚úÖ Setup conclu√≠do!"
echo ""
echo "Pr√≥ximos passos:"
echo "1. Edite o arquivo .env com suas configura√ß√µes"
echo "2. Acesse o EasyPanel em http://$(hostname -I | awk '{print $1}'):3000"
echo "3. Crie um novo projeto e importe o docker-compose.yml"
echo ""
```

### 12.6 Nginx Configuration

```nginx
# docker/nginx.conf
server {
    listen 80;
    server_name _;
    root /usr/share/nginx/html;
    index index.html;

    # Gzip compression
    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml text/javascript;

    # Cache static assets
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # SPA routing - always serve index.html
    location / {
        try_files $uri $uri/ /index.html;
    }

    # Health check
    location /health {
        return 200 'OK';
        add_header Content-Type text/plain;
    }
}
```

### 12.7 Deploy Commands

```bash
# scripts/deploy.sh

#!/bin/bash
set -e

echo "üöÄ Deploying Neural Architect..."

# Load environment
source .env

# Pull latest changes
git pull origin main

# Build and start containers
docker compose -f docker/docker-compose.yml build
docker compose -f docker/docker-compose.yml up -d

# Run migrations
docker compose -f docker/docker-compose.yml exec backend uv run alembic upgrade head

# Show status
docker compose -f docker/docker-compose.yml ps

echo ""
echo "‚úÖ Deploy conclu√≠do!"
echo "üåê Acesse: https://$DOMAIN"
```

---

## 13. REGRAS DE IMPLEMENTA√á√ÉO

### 13.1 Fazer (DO) ‚úÖ

```
FRONTEND:
‚úÖ Usar TypeScript strict mode
‚úÖ Validar com Zod antes de enviar ao backend
‚úÖ Usar React.memo() em componentes de lista
‚úÖ Implementar skeleton loaders (n√£o spinners)
‚úÖ Auto-save a cada 5 segundos no canvas
‚úÖ Manter undo/redo com m√≠nimo 50 estados
‚úÖ SSE para streaming do chat
‚úÖ Dark mode por padr√£o

BACKEND:
‚úÖ Validar com Pydantic em todos endpoints
‚úÖ Usar async/await em todas opera√ß√µes I/O
‚úÖ Implementar rate limiting
‚úÖ Logs estruturados (JSON)
‚úÖ Health check endpoint
‚úÖ Graceful shutdown

AI:
‚úÖ SEMPRE usar Context7 antes de responder sobre libs
‚úÖ Streaming para todas respostas do Partner
‚úÖ Truncar contexto do canvas para economizar tokens
‚úÖ SEMPRE pesquisar as vers√µes mais recentes das libs

DATABASE:
‚úÖ √çndices em foreign keys
‚úÖ Soft delete quando apropriado
‚úÖ Timestamps em todas tabelas
‚úÖ JSONB para dados flex√≠veis
```

### 13.2 N√£o Fazer (DON'T) ‚ùå

```
FRONTEND:
‚ùå N√£o usar spinners (causa ansiedade em TDAH)
‚ùå N√£o bloquear UI durante opera√ß√µes
‚ùå N√£o usar localStorage para dados sens√≠veis
‚ùå N√£o fazer requests em useEffect sem cleanup
‚ùå N√£o ignorar erros de valida√ß√£o Zod

BACKEND:
‚ùå N√£o usar sync operations (sempre async)
‚ùå N√£o expor stack traces em produ√ß√£o
‚ùå N√£o armazenar API keys no c√≥digo
‚ùå N√£o confiar em input do frontend

AI:
‚ùå N√£o assumir que sabe vers√µes atuais (usar Context7)
‚ùå N√£o enviar canvas completo a cada request
‚ùå N√£o usar GPT-4 Turbo (usar Claude)
‚ùå N√£o ignorar rate limits das APIs

DATABASE:
‚ùå N√£o usar SELECT * em queries
‚ùå N√£o fazer N+1 queries
‚ùå N√£o armazenar dados sens√≠veis sem criptografia
```

---

## 14. ACCEPTANCE CRITERIA FINAL

### 14.1 Checklist

```
‚ñ° Project Hub
  ‚ñ° Listar projetos por categoria
  ‚ñ° Criar projeto com nome, descri√ß√£o, categoria
  ‚ñ° Editar projeto
  ‚ñ° Excluir projeto
  ‚ñ° Filtrar por status

‚ñ° Canvas
  ‚ñ° Criar nodes via drag-and-drop
  ‚ñ° Conectar nodes
  ‚ñ° Editar node (label, description)
  ‚ñ° Deletar node/edge
  ‚ñ° Auto-save a cada 5 segundos
  ‚ñ° Undo/Redo (50 estados)
  ‚ñ° Minimap
  ‚ñ° Zoom/Pan

‚ñ° Partner Thinking
  ‚ñ° Chat com streaming
  ‚ñ° Contexto do canvas
  ‚ñ° Context7 integration
  ‚ñ° Sugest√µes de a√ß√µes
  ‚ñ° Gerar fluxos

‚ñ° Document Generator
  ‚ñ° Gerar TIS
  ‚ñ° Gerar PRD
  ‚ñ° Gerar Agent Spec (para categoria agents)
  ‚ñ° Preview do documento
  ‚ñ° Download como Markdown

‚ñ° Deploy
  ‚ñ° Docker Compose funcionando
  ‚ñ° SSL autom√°tico
  ‚ñ° Health checks
  ‚ñ° Logs estruturados
```

---

**FIM DO TIS - Neural Architect v1.0**

*Documento gerado para implementa√ß√£o por IA ou desenvolvedor.*
*Dezembro 2025*